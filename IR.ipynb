{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r\"C:\\Users\\muham\\OneDrive - Universitas Airlangga\\Semester 6\\Sistem Temu Kembali Informasi\\Tugas dan Latihan\\Final tugas akhir\\ALL FILE CSV\\all_file.csv\"\n",
    "stopword_id = r'C:\\Users\\muham\\OneDrive - Universitas Airlangga\\Semester 6\\Sistem Temu Kembali Informasi\\Tugas dan Latihan\\Final tugas akhir\\stopwords-id.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judul: Undang-Undang Nomor 1 Tahun 2023\n",
      "Similarity: 0.3010\n",
      "\n",
      "Judul: Undang-Undang Nomor 31 Tahun 1999\n",
      "Similarity: 0.1694\n",
      "\n",
      "Judul: Undang-Undang Nomor 20 Tahun 2001\n",
      "Similarity: 0.1491\n",
      "\n",
      "Judul: Undang-Undang Nomor 21 Tahun 2007\n",
      "Similarity: 0.1349\n",
      "\n",
      "Judul: Undang-Undang Nomor 4 Tahun 1976\n",
      "Similarity: 0.1106\n",
      "\n",
      "Judul: Undang-Undang Nomor 11 Tahun 1980\n",
      "Similarity: 0.1008\n",
      "\n",
      "Judul: Undang-Undang Nomor 5 Tahun 2018\n",
      "Similarity: 0.0993\n",
      "\n",
      "Judul: Undang-Undang Nomor 27 Tahun 1999\n",
      "Similarity: 0.0945\n",
      "\n",
      "Judul: Undang-Undang Nomor 3 Tahun 1971\n",
      "Similarity: 0.0935\n",
      "\n",
      "Judul: Undang-Undang Nomor 4 Tahun 1958\n",
      "Similarity: 0.0910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import string\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import Memory\n",
    "\n",
    "# Caching setup\n",
    "location = './cache'\n",
    "memory = Memory(location, verbose=0)\n",
    "\n",
    "# Inisialisasi stemmer bahasa Indonesia\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# Membaca daftar stop words bahasa Indonesia\n",
    "with open(stopword_id, 'r') as f:\n",
    "    stop_words_id = f.read().splitlines()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Pastikan text adalah string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # Menghilangkan karakter berulang\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "    \n",
    "    # Menghilangkan angka\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    \n",
    "    # Menghilangkan tanda baca\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Mengubah teks menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Melakukan stemming pada teks\n",
    "    text = stemmer.stem(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "@memory.cache\n",
    "def preprocess_parallel(text_series):\n",
    "    return Parallel(n_jobs=-1)(delayed(preprocess_text)(text) for text in text_series)\n",
    "\n",
    "# Membaca file CSV\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "# Pastikan tidak ada nilai NaN dan semua nilai adalah string\n",
    "df['Teks'] = preprocess_parallel(df['Teks'].fillna(''))\n",
    "\n",
    "# Inisialisasi TfidfVectorizer dengan stop words bahasa Indonesia\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words_id, max_df=0.85, min_df=2, ngram_range=(1, 2))\n",
    "\n",
    "# Melakukan fit dan transformasi pada kolom Teks\n",
    "tfidf_matrix = tfidf.fit_transform(df['Teks'])\n",
    "\n",
    "def search_documents(query, top_n=10):\n",
    "    # Preprocessing query\n",
    "    query = preprocess_text(query)\n",
    "    \n",
    "    # Transformasi query menjadi vektor tf-idf\n",
    "    query_vec = tfidf.transform([query])\n",
    "    \n",
    "    # Menghitung cosine similarity antara query dan semua dokumen\n",
    "    cosine_similarities = linear_kernel(query_vec, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Mendapatkan indeks dokumen dengan similarity tertinggi\n",
    "    related_docs_indices = cosine_similarities.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    # Mendapatkan judul, teks, dan nilai similarity dari dokumen yang relevan\n",
    "    results = [(df.iloc[i]['Judul'], df.iloc[i]['Teks'], cosine_similarities[i], i) for i in related_docs_indices]\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Contoh penggunaan\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"pidana pencurian\"\n",
    "    results = search_documents(query)\n",
    "    for title, text, similarity, doc_index in results:\n",
    "        print(f\"Judul: {title}\")\n",
    "        print(f\"Similarity: {similarity:.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokumen 1:\n",
      "Judul: Undang-Undang Nomor 1 Tahun 2023\n",
      "Teks: salinanmenimbangfresidenrepubuk indonesiaundangundang republik indonesianomor tahun tentangkitab undangundang hukum pidanadengan rahmat tuhan yang maha esapresiden republik indonesiaabahwa untuk wujud...\n",
      "Similarity: 0.3010\n",
      "Dokumen 2:\n",
      "Judul: Undang-Undang Nomor 31 Tahun 1999\n",
      "Teks: presiden republik indonesia undangundang republik indonesia nomor tahun tentang berantas tindak pidana korupsi dengan rahmat tuhan yang maha esa presiden republik indonesia timbang a bahwa tindak pida...\n",
      "Similarity: 0.1694\n",
      "Dokumen 3:\n",
      "Judul: Undang-Undang Nomor 20 Tahun 2001\n",
      "Teks: presidenrepublik indonesiaundang undang republik indones ianomor tahun tentangperubahan atas undang undang nomor tahun tentang berantas tindak pidana korupsidengan rahmat tuhan yang maha esapresiden r...\n",
      "Similarity: 0.1491\n",
      "Dokumen 4:\n",
      "Judul: Undang-Undang Nomor 21 Tahun 2007\n",
      "Teks: undangundang republik indonesianomor tahun tentangpemberantasan tindak pidana dagang orangdengan rahmat tuhan yang maha esapresiden republik indonesiamenimbang a bahwa tiap orang bagai makhluk tuhan y...\n",
      "Similarity: 0.1349\n",
      "Dokumen 5:\n",
      "Judul: Undang-Undang Nomor 4 Tahun 1976\n",
      "Teks: undangundang republik indonesia nomor tahun tentang ubah dan tambah beberapa pasal dalam kitab undangundang hukum pidana tali dengan luas laku tentu perundangundangan pidana jahat terbang dan jahat ha...\n",
      "Similarity: 0.1106\n",
      "Dokumen 6:\n",
      "Judul: Undang-Undang Nomor 11 Tahun 1980\n",
      "Teks: undangundang republik indonesia nomor tahun tentang tindak pidana suap dengan rahmat tuhan yang maha esa presiden republik indonesia timbang a bahwa buat suap dalam pelbagai bentuk dan sifat di luar y...\n",
      "Similarity: 0.1008\n",
      "Dokumen 7:\n",
      "Judul: Undang-Undang Nomor 5 Tahun 2018\n",
      "Teks: lembar negara republik indonesia no hukum pidana terorisme berantas jelas dalam tambah lembar negara republik indonesia nomor undang undang republik indonesia nomor tahun tentang perub ahan atas undan...\n",
      "Similarity: 0.0993\n",
      "Dokumen 8:\n",
      "Judul: Undang-Undang Nomor 27 Tahun 1999\n",
      "Teks: presiden republik indonesia undangundang republik indonesia nomor tahun tentang ubah kitabkitab undangundang hukum pidana yang kait dengan jahat hadap aman negara dengan rahmat tuhan yang maha esa pre...\n",
      "Similarity: 0.0945\n",
      "Dokumen 9:\n",
      "Judul: Undang-Undang Nomor 3 Tahun 1971\n",
      "Teks: presidenrepublik indonesiaundang undang republik indonesianomor tahun tentangpemberantasan tindak pidana korupsidengan rahmat tuhan yang maha esapresiden republik indonesia timbang a bahwa buat buat k...\n",
      "Similarity: 0.0935\n",
      "Dokumen 10:\n",
      "Judul: Undang-Undang Nomor 4 Tahun 1958\n",
      "Teks: undangundang republik indonesia u nomor tahun tentang tetap undangundang darurat no tahun tentang ancam hukum hadap beli serah dan kuas kepunyan dian atau dalam milik simpan angkut atau pembawan kawat...\n",
      "Similarity: 0.0910\n",
      "\n",
      "\n",
      " -- HASIL PENELUSURAN ULANG -- \n",
      "\n",
      "\n",
      "Judul: Undang-Undang Nomor 1 Tahun 2023\n",
      "Similarity: 0.6581\n",
      "\n",
      "Judul: Undang-Undang Nomor 31 Tahun 1999\n",
      "Similarity: 0.5778\n",
      "\n",
      "Judul: Undang-Undang Nomor 20 Tahun 2001\n",
      "Similarity: 0.5388\n",
      "\n",
      "Judul: Undang-Undang Nomor 21 Tahun 2007\n",
      "Similarity: 0.4589\n",
      "\n",
      "Judul: Undang-Undang Nomor 3 Tahun 1971\n",
      "Similarity: 0.4496\n",
      "\n",
      "Judul: Undang-Undang Nomor 5 Tahun 2018\n",
      "Similarity: 0.3859\n",
      "\n",
      "Judul: Undang-Undang Nomor 46 Tahun 2009\n",
      "Similarity: 0.3550\n",
      "\n",
      "Judul: Undang-Undang Nomor 30 Tahun 2002\n",
      "Similarity: 0.3134\n",
      "\n",
      "Judul: Undang-Undang Nomor 8 Tahun 1981\n",
      "Similarity: 0.2789\n",
      "\n",
      "Judul: Undang-Undang Nomor 12 Tahun 2022\n",
      "Similarity: 0.2708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "def get_feedback(results):\n",
    "    feedback = []\n",
    "    for idx, (title, text, similarity, doc_index) in enumerate(results):\n",
    "        print(f\"Dokumen {idx + 1}:\")\n",
    "        print(f\"Judul: {title}\")\n",
    "        print(f\"Teks: {text[:200]}...\")  # Display only the first 200 characters\n",
    "        print(f\"Similarity: {similarity:.4f}\")\n",
    "        relevansi = int(input(\"Masukkan nilai relevansi (1-5): \"))\n",
    "        feedback.append((doc_index, relevansi))\n",
    "    return feedback\n",
    "\n",
    "def optimize_with_feedback(feedback, tfidf_matrix):\n",
    "    relevant_docs = [idx for idx, relevansi in feedback if relevansi >= 3]\n",
    "    non_relevant_docs = [idx for idx, relevansi in feedback if relevansi < 3]\n",
    "    \n",
    "    if not relevant_docs:\n",
    "        print(\"Tidak ada dokumen yang dianggap relevan. Pencarian ulang tidak dapat dilakukan.\")\n",
    "        return None\n",
    "    \n",
    "    relevant_matrix = tfidf_matrix[relevant_docs]\n",
    "    non_relevant_matrix = tfidf_matrix[non_relevant_docs] if non_relevant_docs else np.zeros(relevant_matrix.shape)\n",
    "    \n",
    "    # Compute the centroid of relevant and non-relevant documents\n",
    "    relevant_centroid = np.asarray(relevant_matrix.mean(axis=0)).flatten()\n",
    "    non_relevant_centroid = np.asarray(non_relevant_matrix.mean(axis=0)).flatten() if non_relevant_docs else np.zeros(relevant_centroid.shape)\n",
    "    \n",
    "    # Update query vector by moving it towards the relevant centroid and away from the non-relevant centroid\n",
    "    def adjust_query_vec(query_vec, relevant_centroid, non_relevant_centroid, alpha=1, beta=0.75, gamma=0.15):\n",
    "        return alpha * query_vec + beta * relevant_centroid - gamma * non_relevant_centroid\n",
    "    \n",
    "    return adjust_query_vec\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"pidana pencurian\"\n",
    "    initial_results = search_documents(query)\n",
    "    \n",
    "    feedback = get_feedback(initial_results)\n",
    "    adjust_query_vec = optimize_with_feedback(feedback, tfidf_matrix)\n",
    "    \n",
    "    if adjust_query_vec:\n",
    "        relevant_docs = [idx for idx, relevansi in feedback if relevansi >= 3]\n",
    "        non_relevant_docs = [idx for idx, relevansi in feedback if relevansi < 3]\n",
    "        \n",
    "        # Reprocess the query with the adjusted query vector\n",
    "        query_vec = tfidf.transform([preprocess_text(query)])\n",
    "        adjusted_query_vec = adjust_query_vec(query_vec.toarray(), np.asarray(tfidf_matrix[relevant_docs].mean(axis=0)).flatten(), \n",
    "                                              np.asarray(tfidf_matrix[non_relevant_docs].mean(axis=0)).flatten() if non_relevant_docs else np.zeros(query_vec.shape))\n",
    "        \n",
    "        # Compute cosine similarity with the adjusted query vector\n",
    "        cosine_similarities = linear_kernel(adjusted_query_vec, tfidf_matrix).flatten()\n",
    "        related_docs_indices = cosine_similarities.argsort()[-10:][::-1]\n",
    "        \n",
    "        # Display optimized results\n",
    "        optimized_results = [(df.iloc[i]['Judul'], df.iloc[i]['Teks'], cosine_similarities[i]) for i in related_docs_indices]\n",
    "        print(\"\\n\\n -- HASIL PENELUSURAN ULANG -- \\n\\n\")\n",
    "        for title, text, similarity in optimized_results:\n",
    "            print(f\"Judul: {title}\")\n",
    "            print(f\"Similarity: {similarity:.4f}\")\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
